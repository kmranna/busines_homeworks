{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TASK: Forecasting demand for 5 weeks of december 2019"
      ],
      "metadata": {
        "id": "jHEbwnEzhPgi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports**"
      ],
      "metadata": {
        "id": "DJUI-d3qITQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "zCjKc_A_IPd2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data loading**"
      ],
      "metadata": {
        "id": "hPDl6FTGIV88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = pd.read_csv('train.csv', delimiter=',')\n",
        "all_data['period_start_dt'] = pd.to_datetime(all_data['period_start_dt'])\n",
        "all_data.rename(columns={'Unnamed: 0': 'id'}, inplace=True)"
      ],
      "metadata": {
        "id": "D0oMVqhEJTRx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"All records: {len(all_data)}\")\n",
        "print(f\"With demand (train): {all_data['demand'].notna().sum()}\")\n",
        "print(f\"Without demand (test): {all_data['demand'].isna().sum()}\")\n",
        "print(f\"\\nPeriod of data: {all_data['period_start_dt'].min().date()} — {all_data['period_start_dt'].max().date()}\")\n",
        "print(f\"\\nProducts: {all_data['product_rk'].nunique()}\")\n",
        "print(f\"Stores: {all_data['store_location_rk'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDmLInuIRXrw",
        "outputId": "49168f30-e827-4a1c-9e66-01db54871d91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All records: 35344\n",
            "With demand (train): 34144\n",
            "Without demand (test): 1200\n",
            "\n",
            "Period of data: 2016-12-19 — 2019-12-30\n",
            "\n",
            "Products: 6\n",
            "Stores: 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis revealed that store 309 has non typical demand pattern - deletion increases quality of a model"
      ],
      "metadata": {
        "id": "Fs270NPVRSHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "store_309 = all_data[all_data['store_location_rk'] == 309]\n",
        "print(f\"Store 309:\")\n",
        "print(f\"   Records: {len(store_309)}\")\n",
        "print(f\"   Missings in demand: {store_309['demand'].isna().sum()}\")\n",
        "print(f\"   First date: {store_309['period_start_dt'].min().date()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1GTByqtR7x_",
        "outputId": "1d35ecbc-4c6b-49c7-e159-3c894d894480"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Store 309:\n",
            "   Records: 15\n",
            "   Missings in demand: 0\n",
            "   First date: 2016-12-19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = all_data[all_data['store_location_rk'] != 309].copy()"
      ],
      "metadata": {
        "id": "ozuBSlEcSQ_O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nStore 309 deleted. Remaining records: {len(all_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0OhHm_6SaMS",
        "outputId": "b1eb729c-3d10-4158-9c00-d2b8855a8060"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Store 309 deleted. Remaining records: 35329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data split**"
      ],
      "metadata": {
        "id": "sy5w5mmsSwvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = all_data[all_data['demand'].notna()].copy()\n",
        "test_data = all_data[all_data['demand'].isna()].copy()"
      ],
      "metadata": {
        "id": "4CHKw0eXIdBx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" Train: {len(train_data)} records\")\n",
        "print(f\" Test: {len(test_data)} records\")\n",
        "\n",
        "print(f\"\\n Test weeks (for prediction):\")\n",
        "for dt in sorted(test_data['period_start_dt'].unique()):\n",
        "    week_num = (dt.day - 1) // 7 + 1\n",
        "    print(f\"   {dt.date()} - week {week_num} of december\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9CkHzztS0IS",
        "outputId": "4fdf221e-9f4c-4751-fc40-bef6e4319f2b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Train: 34129 records\n",
            " Test: 1200 records\n",
            "\n",
            " Test weeks (for prediction):\n",
            "   2019-12-02 - week 1 of december\n",
            "   2019-12-09 - week 2 of december\n",
            "   2019-12-16 - week 3 of december\n",
            "   2019-12-23 - week 4 of december\n",
            "   2019-12-30 - week 5 of december\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper functions"
      ],
      "metadata": {
        "id": "cH_qMsFeIgCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Returns number of week in december"
      ],
      "metadata": {
        "id": "SCThsidMTggU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dec_week(dt):\n",
        "    return (dt.day - 1) // 7 + 1"
      ],
      "metadata": {
        "id": "Bdd72l1LTZGj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finds combinations (product, store) with 0 demand over last n weeks\n",
        "\n",
        "It may mean that product was discontinued in the store, is out of stock and will not appear again, or there is no demand for product in the store\n",
        "\n",
        "In such cases forecast = 0 is better than a model prediction\n",
        "\n",
        "- experiments showed that n_weeks=5 is the best"
      ],
      "metadata": {
        "id": "mucwLpUMTnaK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_zero_combinations(train_df, n_weeks):\n",
        "    train_df = train_df.sort_values(['product_rk', 'store_location_rk', 'period_start_dt'])\n",
        "    last_date = train_df['period_start_dt'].max()\n",
        "    cutoff = last_date - pd.Timedelta(weeks=n_weeks-1)\n",
        "    recent = train_df[train_df['period_start_dt'] >= cutoff]\n",
        "    zero_combos = recent.groupby(['product_rk', 'store_location_rk'])['demand'].sum()\n",
        "    return set(zero_combos[zero_combos == 0].index.tolist())"
      ],
      "metadata": {
        "id": "TbI2zo9kTbn9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Patterns"
      ],
      "metadata": {
        "id": "wGgwyo_BawKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pattern preparation for december**"
      ],
      "metadata": {
        "id": "EbwyNPQfTey4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "December 2018 - best base\n",
        "\n",
        "- It is the last full december before foorecast period\n",
        "- Unique seasonality (normal demand -> growth -> peak demand due to New Year)\n",
        "\n",
        "December 2018 is used for baseline demand level for product x store pairs and weekly patterns within december"
      ],
      "metadata": {
        "id": "oiWPVop5V4HK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dec_2018 = train_data[(train_data['period_start_dt'] >= '2018-12-01') &\n",
        "                       (train_data['period_start_dt'] <= '2018-12-31')].copy()\n",
        "dec_2018['dec_week'] = dec_2018['period_start_dt'].apply(get_dec_week)"
      ],
      "metadata": {
        "id": "S7a5Kf28XQ7Z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" December 2018: {len(dec_2018)} records\")\n",
        "print(f\"\\n Mean demand by december 2018 weeks:\")\n",
        "\n",
        "week_demand = dec_2018.groupby('dec_week')['demand'].mean()\n",
        "for week, demand in week_demand.items():\n",
        "    print(f\"   Week {week}: {demand:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh-vlM4uXZNf",
        "outputId": "7795d9e0-792c-4742-a628-a16443221329"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " December 2018: 1185 records\n",
            "\n",
            " Mean demand by december 2018 weeks:\n",
            "   Week 1: 9.04\n",
            "   Week 2: 11.42\n",
            "   Week 3: 19.58\n",
            "   Week 4: 37.00\n",
            "   Week 5: 39.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Global and product patterns**"
      ],
      "metadata": {
        "id": "CJRfwwCbapWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Global* - average ratio of each week to total month (for all products)\n",
        "- Used as a fallback if there is no product specific dataavailable\n",
        "\n",
        "*Product level* — ratio for each product calculated separately\n",
        "- Different products show different patterns in december"
      ],
      "metadata": {
        "id": "4JyYFJiVcAI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_mean = dec_2018['demand'].mean()\n",
        "print(f\"Global mean december 2018: {global_mean:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se5qJhIVay5y",
        "outputId": "6f227492-7cf9-462c-819a-377d86b83f5c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global mean december 2018: 23.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_week_ratios = (dec_2018.groupby('dec_week')['demand'].mean() / global_mean).to_dict()\n",
        "\n",
        "print(f\"\\n Global week coefficients:\")\n",
        "for week, ratio in global_week_ratios.items():\n",
        "    trend = \"up\" if ratio > 1 else \"down\"\n",
        "    print(f\"   Week {week}: {ratio:.3f} {trend}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHKDxJFsbJ82",
        "outputId": "91acfade-e7de-4b9f-d6e6-909b7565dd63"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Global week coefficients:\n",
            "   Week 1: 0.387 down\n",
            "   Week 2: 0.489 down\n",
            "   Week 3: 0.838 down\n",
            "   Week 4: 1.584 up\n",
            "   Week 5: 1.679 up\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "product_dec_mean = dec_2018.groupby('product_rk')['demand'].mean().to_dict()\n",
        "\n",
        "product_week_ratios = {}\n",
        "\n",
        "# coefficient = demand in this week / mean demand for a product in a month\n",
        "for (prod, week), demand in dec_2018.groupby(['product_rk', 'dec_week'])['demand'].mean().items():\n",
        "    product_week_ratios[(prod, week)] = demand / product_dec_mean[prod]"
      ],
      "metadata": {
        "id": "mwXGZTZMbfn2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**YOY trend - year over year**"
      ],
      "metadata": {
        "id": "UXU9CpTTXuOI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing november 2019 with november 2018 in order to know\n",
        "- Demand has increased or decreased for each product x store pair\n",
        "- By what percentage\n",
        "\n",
        "November is used as it is last month before forecast (it is known)\n",
        "\n",
        "TREND_WEIGHT = 0.30"
      ],
      "metadata": {
        "id": "6M6eSTptYEGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nov_2019 = train_data[(train_data['period_start_dt'] >= '2019-11-01') &\n",
        "                       (train_data['period_start_dt'] <= '2019-11-30')]\n",
        "nov_2018 = train_data[(train_data['period_start_dt'] >= '2018-11-01') &\n",
        "                       (train_data['period_start_dt'] <= '2018-11-30')]\n",
        "\n",
        "# mean demand for each combination product x store\n",
        "nov_2019_agg = nov_2019.groupby(['product_rk', 'store_location_rk'])['demand'].mean()\n",
        "nov_2018_agg = nov_2018.groupby(['product_rk', 'store_location_rk'])['demand'].mean()"
      ],
      "metadata": {
        "id": "uKFHNzCBYDTq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trend = november 2019 / november 2019\n",
        "# bound values from 0.3 to 3.0 - to avoid extreme values\n",
        "yoy_trend = (nov_2019_agg / nov_2018_agg.replace(0, np.nan)).fillna(1.0).clip(0.3, 3.0).to_dict()"
      ],
      "metadata": {
        "id": "u2Ulimz7dBsu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trend_values = list(yoy_trend.values())\n",
        "print(f\"\\n Statistics of YoY trend:\")\n",
        "print(f\"   Mean: {np.mean(trend_values):.3f}\")\n",
        "print(f\"   Median: {np.median(trend_values):.3f}\")\n",
        "print(f\"   Min: {np.min(trend_values):.3f}\")\n",
        "print(f\"   Max: {np.max(trend_values):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vkESXA3dZUa",
        "outputId": "21a80920-16c0-4315-c321-443b39014a01"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Statistics of YoY trend:\n",
            "   Mean: 0.938\n",
            "   Median: 0.929\n",
            "   Min: 0.300\n",
            "   Max: 3.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if np.mean(trend_values) < 1:\n",
        "    print(f\"\\n Mean trend < 1 -> demand in 2019 lower than in 2018\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqBucTwddpOZ",
        "outputId": "727844bc-9d24-4823-a22e-163e0ea9b14d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Mean trend < 1 -> demand in 2019 lower than in 2018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparation of base demand**"
      ],
      "metadata": {
        "id": "_y8Ze9QZdsM7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each combination product x store determine the baseline demand level\n",
        "\n",
        "Priority of sources\n",
        "-  Average from December 2018 - best source\n",
        "- Average from the latest data × December/November coeff - fallback\n",
        "- Product level average - if no store specific data available\n",
        "- Global average"
      ],
      "metadata": {
        "id": "RDAazh8HdxYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_demand = dec_2018.groupby(['product_rk', 'store_location_rk'])['demand'].mean().to_dict()\n",
        "print(f\"Base from december 2018: {len(base_demand)} combinations\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrS_hlVeeNIW",
        "outputId": "0755e1f2-0e7c-4c74-cbef-4b82a3a7c47d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base from december 2018: 239 combinations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recent = train_data[train_data['period_start_dt'] >= '2019-10-01']\n",
        "recent_base = recent.groupby(['product_rk', 'store_location_rk'])['demand'].mean().to_dict()\n",
        "print(f\"Fallback from recent data: {len(recent_base)} combinations\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ex7PZIieWgO",
        "outputId": "432d270a-059d-439d-8f64-c4a908b97bd1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fallback from recent data: 240 combinations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dec_to_nov_ratio = dec_2018['demand'].mean() / nov_2018['demand'].mean()\n",
        "print(f\"Coefficient december/november: {dec_to_nov_ratio:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OFciB9BehIZ",
        "outputId": "30ad983a-09c0-4915-e704-8b5a0b32114a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficient december/november: 2.175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "iO2sWArMe3BZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rule for zeros - if the product was not sold for n weeks in the store it is likely that it would not be sold in december too"
      ],
      "metadata": {
        "id": "MD9snQ9Ie4So"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ZERO_WEEKS = 5\n",
        "\n",
        "zero_combinations = find_zero_combinations(train_data, n_weeks=ZERO_WEEKS)"
      ],
      "metadata": {
        "id": "IFbi5M7PfXEK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Combinations with 0 demand: {len(zero_combinations)}\")\n",
        "print(f\"{len(zero_combinations) / len(test_data) * 100:.1f}% from test records\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_TTa6LVfgKp",
        "outputId": "64db32bf-99b5-48ee-e87d-8fc93a2adb25"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combinations with 0 demand: 35\n",
            "2.9% from test records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Week corrections**"
      ],
      "metadata": {
        "id": "WQXH_ALsfuRu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These coefficients adjust the forecast for each week of december"
      ],
      "metadata": {
        "id": "Pqtq6EyGfyEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WEEK_CORRECTIONS = {1: 0.92, 2: 0.92, 3: 0.89, 4: 0.97, 5: 1.06}"
      ],
      "metadata": {
        "id": "04j97xJRe93e"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weight for YOY trend"
      ],
      "metadata": {
        "id": "bwsSn5pjgBFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TREND_WEIGHT = 0.30"
      ],
      "metadata": {
        "id": "TlNMIQvjgE_W"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forecast"
      ],
      "metadata": {
        "id": "S2lLPfxogKrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for _, row in test_data.iterrows():\n",
        "    product = row['product_rk']\n",
        "    store = row['store_location_rk']\n",
        "    week = get_dec_week(row['period_start_dt'])\n",
        "    combo = (product, store)\n",
        "\n",
        "    # zero rule\n",
        "    if combo in zero_combinations:\n",
        "        predictions.append(0)\n",
        "        continue\n",
        "\n",
        "    # base\n",
        "    base = base_demand.get(combo)\n",
        "    if base is None:\n",
        "        base = recent_base.get(combo)\n",
        "        if base is not None:\n",
        "            base = base * dec_to_nov_ratio\n",
        "        else:\n",
        "            base = product_dec_mean.get(product, global_mean)\n",
        "\n",
        "    # week pattern\n",
        "    week_ratio = product_week_ratios.get((product, week), global_week_ratios.get(week, 1.0))\n",
        "\n",
        "    # trend\n",
        "    trend = yoy_trend.get(combo, 1.0)\n",
        "    trend_adjusted = 1 + (trend - 1) * TREND_WEIGHT\n",
        "\n",
        "    # final prediction\n",
        "    pred = base * week_ratio * WEEK_CORRECTIONS[week] * trend_adjusted\n",
        "    predictions.append(max(pred, 0))"
      ],
      "metadata": {
        "id": "_T2M9OykgMYp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save submission"
      ],
      "metadata": {
        "id": "r8lZXPtsgWhu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OpsziUtCGlQf"
      },
      "outputs": [],
      "source": [
        "submission = test_data[['id']].copy()\n",
        "submission['predicted'] = predictions\n",
        "submission.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Path to the final solution"
      ],
      "metadata": {
        "id": "9dk940FzhbEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 - initial approach — ML with lag features**\n",
        "\n",
        "*What I tried*\n",
        "\n",
        "LightGBM with 606 features\n",
        "\n",
        "- lags 1–4 weeks and 1 year\n",
        "- rolling means (14D, 28D, 56D, 84D)\n",
        "- EWMs with different alphas\n",
        "- aggregations\n",
        "\n",
        "Validation was on November 2019\n",
        "\n",
        "*Results*\n",
        "\n",
        "SMAPE around 79 — very poor\n",
        "\n",
        "*Why it didn’t work*\n",
        "\n",
        "- Overfitting - 606 features on 34k records — model captured noise\n",
        "- Lag features became NaN for forecast weeks — model loose information\n",
        "- December has unique seasonality which lags cannot capture"
      ],
      "metadata": {
        "id": "2vdbh7bCj0FT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2 - model simplification**\n",
        "\n",
        "*What I tried*\n",
        "- Reducing feature set from 606 to around 50 - only basic lags and calendar f eatures\n",
        "\n",
        "*Results*\n",
        "\n",
        "SMAPE 68 — improvement\n",
        "\n",
        "*Why it worked*\n",
        "\n",
        "Fewer features -> less noise -> less overfitting."
      ],
      "metadata": {
        "id": "kkeu4usLlpzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3 - december seasonality analysis**\n",
        "\n",
        "*From analysis*\n",
        "- December - significantly different from other months — demand rises toward the  New Year\n",
        "- Last full december in dataset - 2018.\n",
        "- Pattern within december: week 1 (9 units), week 5 (39 units) — approximately 4x increase\n",
        "\n",
        "*What I tried*\n",
        "- I used december 2018 as a base for forecast\n",
        "- Calculated week_ratio = weekly_demand / monthly_demand\n",
        "- Formula: predicted = base x week_ratio\n",
        "\n",
        "*Results*\n",
        "- SMAPE 62 — another improvement\n",
        "\n",
        "*Conclusion*\n",
        "December 2018 - best predictor of december 2019 as\n",
        "- closest full december\n",
        "- contains the same New Year seasonality\n",
        "- has the same stores and products"
      ],
      "metadata": {
        "id": "cbydK-DYmNNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4 - add YoY trend**\n",
        "\n",
        "*From analysis*\n",
        "- demand in 2019 may change compared to 2018 (store growth/decline)\n",
        "- november 2019 compared to November 2018 reflects current state of each pair product x store\n",
        "\n",
        "*What I tried*\n",
        "- calculated yoy_trend = nov_2019 / nov_2018 - for each combination\n",
        "- capped it to [0.3, 3.0] - to avoid extremes\n",
        "- predicted = base x week_ratio x trend\n",
        "\n",
        "*Results*\n",
        "- with full trend (100%) - performance worsened — the trend is too noisy\n",
        "- with trend_weight = 0.3: SMAPE 57 — an improvement"
      ],
      "metadata": {
        "id": "xouyIhzIncEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5 - grid search for weekly corrections\n",
        "\n",
        "*From analysis*\n",
        "- model overestimate the beginning of the month and underestimate the end\n",
        "- weekly correction coefficients are needed\n",
        "\n",
        "*What I tried*\n",
        "- grid search over w1, w2, w3, w4, w5 in the range [0.90, 1.10]\n",
        "- combinations - evaluated using average predictions and validation\n",
        "\n",
        "*Results*\n",
        "- Best combination: {1: 0.96, 2: 0.96, 3: 0.94, 4: 0.98, 5: 1.02}\n",
        "- SMAPE 56 — small improvement\n",
        "\n",
        "*Why it worjed*\n",
        "- week 3 requires strong reduction — base model seems to overestimate it\n",
        "- week 5 needs an increase — the New Year peak was underestimated"
      ],
      "metadata": {
        "id": "MZChFe5eoYOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6 - zero rule — main breakthrough**\n",
        "\n",
        "*Logic*\n",
        "\n",
        "If the product was not sold for n weeks in a store then most likely\n",
        "\n",
        "- product has been discontinued\n",
        "- no restocks\n",
        "- no demand in this store\n",
        "\n",
        "In all cases forecast=0 - more accurate than models\n",
        "\n",
        "*What I tried*\n",
        "- implemented rule with n_weeks = 8 initially\n",
        "- found 165 combinations with 0 demand - forecast to 0\n",
        "\n",
        "*Results*\n",
        "- SMAPE 50 —  beat 1 benchmark\n",
        "\n",
        "*Why it worked*\n",
        "- SMAPE heavily penalizes forecasts > 0 if the real value is 0\n",
        "- setting false positives to zero - removes penalties\n",
        "\n",
        "**Step 6.1 - zero rule optimisation**\n",
        "\n",
        "*What I tried*\n",
        "- n_weeks=2, 3, 4, 5, 6, 7, 8, 10, 12\n",
        "\n",
        "*Results*\n",
        "- 5 is the best for private score, 2 - best for public"
      ],
      "metadata": {
        "id": "G0IPI2G8pGhg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8 - optimisation of other parameters**\n",
        "\n",
        "*What I tried*\n",
        "- grid search: w1, w2, w3, w4, w5, trend_weight with fixed zero_weeks=5\n",
        "\n",
        "*Final parameters*\n",
        "\n",
        "- WEEK_CORRECTIONS = {1: 0.92, 2: 0.92, 3: 0.89, 4: 0.97, 5: 1.06}\n",
        "- TREND_WEIGHT = 0.30\n",
        "- ZERO_WEEKS = 5\n",
        "\n",
        "*Result*\n",
        "\n",
        "- Private SMAPE=48.024 — best result"
      ],
      "metadata": {
        "id": "_k3sRtM1qmtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What did not work"
      ],
      "metadata": {
        "id": "gaxtEVe1qKwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. CatBoost and recursive forecasting  \n",
        "\n",
        "Logic: predict week by week with previous forecasts as lag features\n",
        "\n",
        "Result: SMAPE 74–76 — bad\n",
        "\n",
        "Why: Accumulation of errors (week 1 error -> distorted lags -> 2 error -> etc)\n",
        "\n",
        "2. Promo correction  \n",
        "\n",
        "Logic: PROMO1_FLAG in test - hint. Increase forecast during promo\n",
        "\n",
        "Result: SMAPE 81 — very bad\n",
        "\n",
        "Why: promo multiplier was x3 — too aggressive - it broke the model\n",
        "\n",
        "3. Product or store level corrections  \n",
        "\n",
        "Logic: different coeffs - for different products/stores\n",
        "\n",
        "Result: 57 — not better than base model\n",
        "\n",
        "Why: not enough data to estimate individual coeffs\n",
        "\n",
        "4. Quantile regression  \n",
        "\n",
        "Logic: median instead of mean - better for SMAPE\n",
        "\n",
        "Result: 57 — no improvement\n",
        "\n",
        "Why: in this dataset median ≈ mean.\n",
        "\n",
        "5. Ensembles of ML models\n",
        "\n",
        "Idea: average several CatBoost models with different seeds\n",
        "\n",
        "Result: 74–76 — still bad\n",
        "\n",
        "Why: If base approach is bad - ensemble will not save it\n",
        "\n",
        "6. weighting multiple Decembers (2016, 2017, 2018)  \n",
        "\n",
        "Idea: average patterns across all dcembers\n",
        "\n",
        "Result: 79 — worse than using just 2018\n",
        "\n",
        "Why: older data is less relevant, 2018 is closest to 2019"
      ],
      "metadata": {
        "id": "p23SG80NrmWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key findings"
      ],
      "metadata": {
        "id": "f9QpCzRatktS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- simplicity - 6 parameters instead of 606 features\n",
        "\n",
        "- domain knowledge is critical - zero rule is business logic, not math\n",
        "\n",
        "- december is unique - we cannot make predictions from other months\n",
        "\n",
        "- smoothing - 30% of the trend works better than 100\n",
        "\n",
        "- grid search - works on simple models\n",
        "\n",
        "- ML can work badly on small data with strong seasonality"
      ],
      "metadata": {
        "id": "Be8ZGUj3toFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final solution"
      ],
      "metadata": {
        "id": "mT5L6oL-uOoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**zero rule**\n",
        "\n",
        "if sum of demand for 5 weeks == 0 -> predicted = 0\n",
        "\n",
        "else predicted = base_dec2018 x week_ratio x week_correction x trend_adjusted\n",
        "\n",
        "**parameters**\n",
        "\n",
        "WEEK_CORRECTIONS = {1: 0.92, 2: 0.92, 3: 0.89, 4: 0.97, 5: 1.06}\n",
        "\n",
        "TREND_WEIGHT = 0.30\n",
        "\n",
        "ZERO_WEEKS = 5"
      ],
      "metadata": {
        "id": "jakyGQkRuQ3C"
      }
    }
  ]
}